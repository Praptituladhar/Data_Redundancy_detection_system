{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43a43013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TekBahadurBista280769680Bajuda241 and TekBahadurBista280769680Bajuda241 are duplicates (edit distance = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\range.py\", line 345, in get_loc\n",
      "    return self._range.index(new_key)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: 0 is not in range\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\Python311\\Lib\\tkinter\\__init__.py\", line 1948, in __call__\n",
      "    return self.func(*args)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Yagiten\\AppData\\Local\\Temp\\ipykernel_7164\\6163720.py\", line 96, in upload_file\n",
      "    duplicates = find_duplicates(std_att, threshold=0.05)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Yagiten\\AppData\\Local\\Temp\\ipykernel_7164\\6163720.py\", line 38, in find_duplicates\n",
      "    distance_matrix = apply_edit_distance(strings)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Yagiten\\AppData\\Local\\Temp\\ipykernel_7164\\6163720.py\", line 33, in apply_edit_distance\n",
      "    distance_matrix[i][j] = edit_distance(strings[i], strings[j])\n",
      "                                          ~~~~~~~^^^\n",
      "  File \"C:\\Program Files\\Python311\\Lib\\site-packages\\pandas\\core\\series.py\", line 1012, in __getitem__\n",
      "    return self._get_value(key)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Program Files\\Python311\\Lib\\site-packages\\pandas\\core\\series.py\", line 1121, in _get_value\n",
      "    loc = self.index.get_loc(label)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Program Files\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\range.py\", line 347, in get_loc\n",
      "    raise KeyError(key) from err\n",
      "KeyError: 0\n"
     ]
    }
   ],
   "source": [
    "import tkinter \n",
    "from tkinter import *\n",
    "from tkinter import filedialog \n",
    "# import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "import editdistance\n",
    "import numpy as np\n",
    "\n",
    "def edit_distance(str1, str2):\n",
    "    m, n = len(str1), len(str2)\n",
    "    dp = [[0 for j in range(n + 1)] for i in range(m + 1)]\n",
    "\n",
    "    for i in range(m + 1):\n",
    "        for j in range(n + 1):\n",
    "            if i == 0:\n",
    "                dp[i][j] = j\n",
    "            elif j == 0:\n",
    "                dp[i][j] = i\n",
    "            elif str1[i - 1] == str2[j - 1]:\n",
    "                dp[i][j] = dp[i - 1][j - 1]\n",
    "            else:\n",
    "                dp[i][j] = 1 + min(dp[i][j - 1], dp[i - 1][j], dp[i - 1][j - 1])\n",
    "\n",
    "    return dp[m][n]\n",
    "\n",
    "\n",
    "def apply_edit_distance(strings):\n",
    "    n = len(strings)\n",
    "    distance_matrix = [[0 for j in range(n)] for i in range(n)]\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if i != j:\n",
    "                distance_matrix[i][j] = edit_distance(strings[i], strings[j])\n",
    "    return distance_matrix\n",
    "\n",
    "\n",
    "def find_duplicates(strings, threshold=0.05):\n",
    "    distance_matrix = apply_edit_distance(strings)\n",
    "    n = len(strings)\n",
    "    duplicates = []\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            if distance_matrix[i][j] <= threshold:\n",
    "                duplicates.append((i, j, distance_matrix[i][j]))\n",
    "    duplicates.sort(key=lambda x: x[2])  # sort by edit distance\n",
    "    return duplicates\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def upload_file():\n",
    "    file=filedialog.askopenfilename(title=\"Select file\" , filetypes=[(\"All files\", '*.*'),(\"CSV files\", '.csv')])\n",
    "    # file=filedialog.askopenfilename(title=\"Select file\" , filetypes=[(\"CSV files\", '.csv')])\n",
    "\n",
    "    if(file):\n",
    "        lbl_my_file=Label(window, text=\"File read!\", font=(\"arial\", 12, \"bold\") )\n",
    "        lbl_my_file.pack()\n",
    "\n",
    "        chunk_size=100\n",
    "        df=pd.read_csv(file, chunksize=chunk_size)\n",
    "\n",
    "        file_name.set(file)\n",
    "#         df[\"name\"] = df['name'].str.replace(\" \", \"\")\n",
    "#         std_att = df['name'].astype(str) + df['age'].astype(str) + df['age_unit'].astype(str) + df['province_id'].astype(str) + df['district_id'].astype(str) + df['municipality_id'].astype(str) + df['tole'].astype(str) + df['ward'].astype(str) + df['caste'].astype(str) + df['sex'].astype(str)\n",
    "# #         print (std_attribute)\n",
    "        # df['std_attribute'] = std_att\n",
    "        # sorted_df = df.sort_values(by=['std_attribute'])\n",
    "        # print(sorted_df)\n",
    "\n",
    "\n",
    "        # def process_chunk(chunk):\n",
    "        #     # do some processing on the chunk of data\n",
    "        #     strings = std_att  # Replace ... with the rest of the strings\n",
    "        #     duplicates = find_duplicates(strings, threshold=3)\n",
    "        #     for i, j, distance in duplicates:\n",
    "        #         print(f\"{strings[i]} and {strings[j]} are duplicates (edit distance = {distance})\")\n",
    "        \n",
    "        \n",
    "        # for chunk in df:\n",
    "        #     df[\"name\"] = df['name'].str.replace(\" \", \"\")\n",
    "        #     std_att = df['name'].astype(str) + df['age'].astype(str) + df['age_unit'].astype(str) + df['province_id'].astype(str) + df['district_id'].astype(str) + df['municipality_id'].astype(str) + df['tole'].astype(str) + df['ward'].astype(str) + df['caste'].astype(str) + df['sex'].astype(str)\n",
    "        # # processed_chunk = process_chunk(chunk)\\\n",
    "        #     strings = std_att  # Replace ... with the rest of the strings\n",
    "        #     duplicates = find_duplicates(strings, threshold=0.05)\n",
    "        #     for i, j, distance in duplicates:\n",
    "        #         print(f\"{strings[i]} and {strings[j]} are duplicates (edit distance = {distance})\")\n",
    "\n",
    "        #     chunk=chunk+100\n",
    "        #     # print(processed_chunk)\n",
    "\n",
    "        for chunk in pd.read_csv(file, chunksize=100):\n",
    "            chunk[\"modified_name\"] = chunk[\"name\"].str.replace(\" \", \"\")            \n",
    "            std_att = chunk['modified_name'].astype(str) + chunk['age'].astype(str) + chunk['age_unit'].astype(str) + chunk['province_id'].astype(str) + chunk['district_id'].astype(str) + chunk['municipality_id'].astype(str) + chunk['tole'].astype(str) + chunk['ward'].astype(str) + chunk['caste'].astype(str) + chunk['sex'].astype(str)\n",
    "\n",
    "            # apply the edit distance function to the string array\n",
    "            duplicates = find_duplicates(std_att, threshold=10)\n",
    "            for i, j, distance in duplicates:\n",
    "                print(f\"{std_att[i]} and {std_att[j]} are duplicates (edit distance = {distance})\")\n",
    "\n",
    "            # process the chunk\n",
    "            # processed_chunk = process_chunk(chunk)\n",
    "\n",
    "            # add 100 to each element in the chunk\n",
    "            # processed_chunk += 100\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "####### divide into chunks##########\n",
    "        # print(\"Number of lines present:-\", len(df))\n",
    "\n",
    "        # def iterate_on_total_rows(filename):\n",
    "        #     # Load dataset\n",
    "\n",
    "        #     # Get total number of rows\n",
    "        #     total_rows = len(df)\n",
    "\n",
    "        #     # Define the condition\n",
    "        #     condition_met = False\n",
    "        #     chunk_size = 100\n",
    "        #     num_rows_processed = 0\n",
    "\n",
    "        #     # Iterate over the data in chunks of 100 rows at a time until the condition is met\n",
    "        #     while not condition_met:\n",
    "        #         # Process the next chunk\n",
    "        #         chunk = df.iloc[num_rows_processed : num_rows_processed + chunk_size]\n",
    "        #         num_rows_processed += len(chunk)\n",
    "\n",
    "        #         # Check the condition\n",
    "        #         # For example, stop after processing the first 500 rows\n",
    "        #         if num_rows_processed >= total_rows:\n",
    "        #             condition_met = True\n",
    "\n",
    "        #         # Do something with the processed data\n",
    "        #         # For example, print the first 5 rows in each chunk\n",
    "        #         print(chunk.head(5))\n",
    "\n",
    "\n",
    "\n",
    "#         strings = std_att # Replace ... with the rest of the strings\n",
    "#         distance_matrix = apply_edit_distance(strings)\n",
    "#         print(distance_matrix)\n",
    "\n",
    "\n",
    "\n",
    "#         df['std_attribute'] = std_att\n",
    "#         sorted_df = df.sort_values(by=['std_attribute'])\n",
    "#         print(sorted_df)\n",
    "#         distances = np.zeros((len(sorted_df), len(sorted_df)))\n",
    "#         for i in range(len(sorted_df)):\n",
    "#             print(\"hello\")\n",
    "#             for j in range(i+1, len(sorted_df)):\n",
    "#                 distances[i][j] = levenshtein(sorted_df['std_attribute'].iloc[i], sorted_df['std_attribute'].iloc[j])\n",
    "\n",
    "#                 distances[j][i] = distances[i][j]\n",
    "\n",
    "#         print(\"Distances matrix:\")\n",
    "#         print(distances)\n",
    "   \n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "    \n",
    "window=Tk()\n",
    "window.geometry(\"400x300\")\n",
    "window.title(\"Data Redundancy Detection System\")\n",
    "title_lbl=Label(window, text=\"Upload .csv file\", font=(\"arial\", 30, \"italic bold\"),bd=7)\n",
    "title_lbl.pack()\n",
    "button=Button(window, text=\"Upload File\", relief=RAISED,font=(\"arial\", 15, \"bold\"), width=15, bg=\"light blue\" ,command=upload_file)\n",
    "button.pack()\n",
    "\n",
    "\n",
    "file_name=StringVar()\n",
    "file_data=StringVar()\n",
    "my_file=StringVar()\n",
    "\n",
    "\n",
    "\n",
    "lbl_name=Label(window, textvariable=file_name)\n",
    "lbl_name.pack()\n",
    "\n",
    "\n",
    "\n",
    "# lbl_data=Label(window, textvariable=file_data, relief=GROOVE)\n",
    "# lbl_data.pack()\n",
    "\n",
    "\n",
    "window.mainloop()\n",
    "\n",
    "# lbl_data.pack(ipadx=10, ipady=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832a2b0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
